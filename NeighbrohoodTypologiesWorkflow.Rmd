---
title: "Neighborhood Typologies Workflow"
output: html_notebook
---

```{r load dependencies}
source('proportion_typology.R')
source('neighborhood_clustering.R')
source('Location_Quotient.R')
library(readstata13)
library(haven) 
library(betareg)
library(tidyverse)
library(VGAM)
```

```{r helper function to load chetty data}
load_chetty <- function(){
  if(!file.exists('data/chetty.csv')){ # if we don't have a chetty file
    chetty_full <- read_csv('data/tract_outcomes.zip') # load the fully Atlas
    # chetty pre-process
    # make TRTID10 var
    # select some variables
    chetty <- chetty_full %>%  # take the atlas
      mutate(state = str_extract(str_c('0', state),'\\d\\d$'), # make a tract id var
             county = str_extract(str_c('000', county),'\\d{3}$'),
             tract = str_extract(str_c('00000', tract),'\\d{6}$'),
             TRTID10 = as.numeric(str_c(state, county, tract))) %>% 
      # select the outcomes of interest
      select(state, county, tract, TRTID10, jail_white_pooled_mean, jail_white_pooled_mean_se, jail_black_pooled_mean, jail_black_pooled_mean_se, jail_asian_pooled_mean, jail_asian_pooled_mean_se, jail_hisp_pooled_mean, jail_hisp_pooled_mean_se, kfr_top01_pooled_pooled_mean, kfr_top01_pooled_pooled_mean_se, kfr_top01_white_pooled_mean, kfr_top01_white_pooled_mean_se, kfr_top01_black_pooled_mean, kfr_top01_black_pooled_mean_se, kfr_top01_asian_pooled_mean, kfr_top01_asian_pooled_mean_se, kfr_top01_hisp_pooled_mean, kfr_top01_hisp_pooled_mean_se,kfr_top20_pooled_pooled_mean, kfr_top20_pooled_pooled_mean_se, kfr_top20_white_pooled_mean, kfr_top20_white_pooled_mean_se, kfr_top20_black_pooled_mean, kfr_top20_black_pooled_mean_se, kfr_top20_asian_pooled_mean, kfr_top20_asian_pooled_mean_se, kfr_top20_hisp_pooled_mean, kfr_top20_hisp_pooled_mean_se, kfr_white_pooled_mean, kfr_white_pooled_mean_se, kfr_black_pooled_mean, kfr_black_pooled_mean_se, kfr_asian_pooled_mean, kfr_asian_pooled_mean_se, kfr_hisp_pooled_mean, kfr_hisp_pooled_mean_se, teenbrth_white_female_mean, teenbrth_white_female_mean_se, teenbrth_black_female_mean, teenbrth_black_female_mean_se, teenbrth_asian_female_mean, teenbrth_asian_female_mean_se, teenbrth_hisp_female_mean, teenbrth_hisp_female_mean_se)
    # write a csv
    write_csv(chetty, 'data/chetty.csv')
  } else { # if we do have a chetty file, load it
  chetty <- read_csv('data/chetty.csv')
  }
  return(chetty)
}
# avp helper function
prep_avp_df <- function(y, fitted_values, bins, model_name){
  # grab the model predictions and actual values
  inter_df <- tibble(actual = y, 
                     predicted = fitted_values) %>% 
    # bin the values
    mutate(x_bins = ntile(actual, bins), 
           y_bins =ntile(predicted, bins))
  # group by bins and return averages
  return(bind_cols(inter_df %>% group_by(x_bins) %>% summarise(actual = mean(actual)),
            inter_df %>% group_by(y_bins) %>% summarise(predicted = mean(actual))) %>% mutate(model = model_name))
}

mse_calc <- function(model = NULL, residuals = NULL, fitted_values = NULL, y = NULL){
  if(is.null(residuals)){ # if we aren't given residuals
    if(length(model$residuals)!=0){
      residuals <- model$residuals # try and get them from the model
    }
    else if (!is.null(fitted_values)){
      residuals <- y - fitted_values  # then try and get them from function values
    } else if(is.null(fitted_values)){
      residuals <- model$fitted.values - model$y # then try and get them from a different part of the model
    } else {
      stop("you need to supply a model with residuals or y and fitted values") # throw and error if we can't
    }
  }
  return(sum(residuals^2)/length(residuals)) # return the mse
}

cv_model(formula_call =cbind(jail_count, nonjail_count) ~ prop.nhwht80 + prop.nhblk80 + prop.asian80 + prop.hisp80
         , model = 'vglm', data = incar, k = 5, family = betabinomial)
cv_model <- function(formula_call, data, k = 5, model = 'glm', scoring_function = 'mse_calc', ...){
  model <- match.fun(model)
  scoring_function <- match.fun(scoring_function)
  data <- data %>% select(all.vars(formula_call))
  x <- data %>% select(all.vars(update(formula_call, 1 ~ .)))
  if(any(sapply(x, typeof) %in% c('character', 'factor'))){ # if any are factor variables
    print("making dummies")
    all_vars <- all.vars(update(formula_call, 1 ~ .))
    vars <- names(sapply(x, typeof)[sapply(x, typeof) %in% c('character', 'factor')]) # grab them
    var_form <- formula(paste('~',paste(vars, collapse = ' + '))) # make a formula
    x <- x %>% 
      select(names(sapply(x, typeof)[!sapply(x, typeof) %in% c('character', 'factor')])) %>%
      bind_cols(data.frame(model.matrix(var_form ,data = x))) %>% select(-X.Intercept.) # then dummify them
    y <- data %>% select(all.vars(update(formula_call, . ~ 1)))
    data = bind_cols(y,x)
    if(length(all.vars(update(formula_call, . ~ 1))) >1){
      formula_call <- as.formula(paste('cbind(', paste(all.vars(update(formula_call, . ~ 1)), collapse = ','), 
                          ') ~', 
                          paste(all_vars[all_vars!=vars], collapse = '+'), 
                          ifelse(any(all_vars!=vars), '+',''), 
                          paste(make.names(names(x)), collapse = '+')))
    } else {
      formula_call <- as.formula(paste(all.vars(update(formula_call, . ~ 1)), 
                          '~', 
                          paste(all_vars[all_vars!=vars], collapse = '+'), 
                          ifelse(any(all_vars!=vars), '+',''), 
                          paste(make.names(names(x)), collapse = '+')))
    }
  }
  # split data k ways
  folds = sample.int(k, size = dim(x)[1], replace = TRUE)
  score = c()
  for(i in 1:k){
    df <- data
    df <- df[!colSums(df[folds==i,])==0]
    df <- df[!colSums(df[!folds==i,])==0]
    df_fold <-  df[folds!=i,]
    ivs <- all.vars(update(formula_call, 1 ~ .))
    if(length(all.vars(update(formula_call, . ~ 1))) >1){
      formula_call <- as.formula(paste('cbind(', paste(all.vars(update(formula_call, . ~ 1)), collapse = ','), 
                          ') ~', paste(intersect(ivs, names(df)), collapse = '+')))
    } else {
      formula_call <- as.formula(paste(all.vars(update(formula_call, . ~ 1)), 
                          '~', 
                          paste(intersect(ivs, names(df)), collapse = '+')))
    }
    fold_model <- model(formula_call, data = df_fold, ...)
    score[i] <- scoring_function(fitted_values = predict(fold_model, 
                                                         df[folds==i,] %>% select(all.vars(update(formula_call, 1 ~ .))), 
                                                         type = 'response'), 
                                 y =  df[folds==i,] %>% select(all.vars(update(formula_call, . ~ 1))))
  }
  mean(score)
}
```




```{r prepare for analysis}
if(!file.exists('data/df_full.csv')){ # if we don't have saved data
  df <- read_csv("data/LTDB_Std_1980_fullcount.csv") # get the 1980 census data
  chetty <- load_chetty() # load a reduced version of chetty's atlas
  nh_cluster <- nh_cluster(df) # run Hannah's neighborhood clustering algo and join to census
  df_full <- full_join(df, nh_cluster, by = 'TRTID10')
  race_typology <- race_typology(df) # run Ian's neighborhood typology and joing to census
  df_full <- full_join(df_full, race_typology, by = 'TRTID10')
  l_quotient <- l_quotient(df) # run Shihao's location quotient algo and joing to census
  df_full <- inner_join(df_full, l_quotient, by = 'TRTID10')
  df_full <- full_join(df_full, chetty, by = 'TRTID10') # join all with census
  df_full %>% write_csv('data/df_full.csv')  # and write to csv
} else{ # otherwise read from file
  df_full <- read_csv('data/df_full.csv')
}
```

Model: teen female birth rate in 2010
```{r modeling teen births}
# Selecting the dependent and independent variables and merge into a dataset for teen birth model
teenbirth <- 
  df_full %>%
  select(intersect(starts_with("teenbrth"), ends_with("mean")), starts_with("prop."), 
         starts_with("LQ"), ends_with("dmmy"),contains("type")) %>%
  mutate_all(funs(replace(., is.na(.), 0))) %>%
  mutate(teenbrth_pooled_female_mean = teenbrth_white_female_mean + teenbrth_black_female_mean +
           teenbrth_asian_female_mean + teenbrth_hispanic_female_mean) %>%
  filter(teenbrth_pooled_female_mean > 0)

# Using different independent variables to run the model
model_brth_prop <- betareg(teenbrth_pooled_female_mean ~ prop.nhwht80 + prop.nhblk80 + prop.asian80 + prop.hisp80,
                           data = teenbirth)

model_brth_LQ <- betareg(teenbrth_pooled_female_mean ~ LQ_white_80 + LQ_black_80 + LQ_asian_80 + LQ_native_80, 
                         data = teenbirth)

model_brth_cluster <- betareg(teenbrth_pooled_female_mean ~ wht.clst.dmmy + blk.clst.dmmy + as.clst.dmmy + hisp.clst.dmmy, data = teenbirth)
  
model_brth_ntype <- betareg(teenbrth_pooled_female_mean ~ collapsed_type, data = teenbirth)
```

Actual vs. Predicted Plot of teen birth rate model
```{r actual vs. predicted plot for teen birth rate}
bins = 40 # set the number of bins
 # function which takes a model and spits out a dataframe formatted to make an avp plot

# Plot the result of each model
plot_df_brth <- bind_rows(prep_avp_df(model_brth_cluster, bins, "cluster"),
                          prep_avp_df(model_brth_LQ, bins, "location quotient"),
                          prep_avp_df(model_brth_ntype, bins, "neighborhood type"),
                          prep_avp_df(model_brth_prop, bins, "racial proportion"))

ggplot(plot_df_brth, aes(x = predicted, y = actual, color = model)) +
  geom_point(alpha = .5)+
  geom_abline(aes(slope = 1, intercept = 0), color = 'red')
```

Modeling fraction incarcerated on April 1st 2010. 
```{r modeling incarceration}
# make a df for this DV
incar <- df_full %>%
  select (POP80, starts_with("jail"), starts_with("prop"), ends_with("dmmy"),
          starts_with("LQ"), contains("type")) %>%
  mutate_all(funs(replace(., is.na(.), 0))) %>% 
  mutate(jail_pooled_pooled_mean = jail_white_pooled_mean + jail_black_pooled_mean + jail_asian_pooled_mean + jail_hisp_pooled_mean) %>%
  mutate(jail_count = round(jail_pooled_pooled_mean*POP80),
         nonjail_count = round(POP80 - jail_count)) %>%
  filter(jail_count > 0)

# fit models for proportion, ntype, clustering, and location quotient


model_inc_prop <- vglm(cbind(jail_count, nonjail_count) ~ prop.nhwht80 + prop.nhblk80 + prop.asian80 + prop.hisp80, 
                       data = incar, 
                       family = betabinomial)

model_inc_ntype <- vglm(cbind(jail_count, nonjail_count) ~ collapsed_type, 
                        data = incar,
                        family = betabinomial)

model_inc_cluster <- vglm(cbind(jail_count, nonjail_count) ~ wht.clst.dmmy + blk.clst.dmmy + as.clst.dmmy + hisp.clst.dmmy, 
                          data = incar,
                          family = betabinomial)

model_inc_lq <- vglm(cbind(jail_count, nonjail_count) ~ LQ_white_80 + LQ_black_80 + LQ_asian_80 + LQ_native_80, 
                     data = incar,
                     family = betabinomial)

model_inc_cluster_prop <- vglm(cbind(jail_count, nonjail_count) ~ wht.clst.dmmy + blk.clst.dmmy + as.clst.dmmy + hisp.clst.dmmy + prop.nhwht80 + prop.nhblk80 + prop.asian80 + prop.hisp80, 
                               data = incar,
                               family = betabinomial) 

null_model <- vglm(cbind(jail_count, nonjail_count) ~ 1, 
                               data = incar,
                               family = betabinomial) 
```

Actual vs predicted plots to check in sample fit for incarceration DV
```{r actual vs predicted plots for incarceration}
bins = 40 # set the number of bins
 # function which takes a model and spits out a dataframe formatted to make an avp plot

# row bind the results for each model
plot_df <- bind_rows(prep_avp_df(as.vector(model_inc_cluster@y), as.vector(model_inc_cluster@fitted.values), bins, "cluster"),
          prep_avp_df(as.vector(model_inc_lq@y), as.vector(model_inc_lq@fitted.values), bins, "location quotient"),
          prep_avp_df(as.vector(model_inc_ntype@y), as.vector(model_inc_ntype@fitted.values), bins, "neighborhood type"),
          prep_avp_df(as.vector(model_inc_prop@y), as.vector(model_inc_prop@fitted.values), bins, "racial proportion"),
          prep_avp_df(as.vector(model_inc_cluster_prop@y), as.vector(model_inc_cluster_prop@fitted.values), bins, "clusters + racial proportion")) %>% 
  mutate(race_plus_clusters = if_else(model == "clusters + racial proportion", TRUE, FALSE)) # this mutate line adds a dummy for the model of interest

# plot comparison
ggplot(plot_df, aes(x = predicted, y = actual, color = model, shape = race_plus_clusters)) +
    geom_point(alpha = .5, size = 2.5) +
    geom_abline(aes(slope = 1, intercept = 0), color = 'red')

# mse calc
mean_guess <- mse_calc(residuals = null_model@residuals) # assign the mean guess to a variable
tibble( # make a tibble
  cluster = mse_calc(residuals = model_inc_cluster@residuals), # then for each model
  loc_quotient = mse_calc(residuals = model_inc_lq@residuals),
  neighborhood_type = mse_calc(residuals = model_inc_ntype@residuals),
  proportion = mse_calc(residuals = model_inc_prop@residuals),
  cluster_prop = mse_calc(residuals = model_inc_cluster_prop@residuals)
) %>% gather() %>% # gather to long format
  ggplot(aes(value, key, color = key))+ # and plot
    geom_point()+
    geom_vline(aes(xintercept = mean_guess), color = 'red')+ # make a red vertical line for the mse of just guessing the mean value
    theme_minimal()+ 
    theme(legend.position = 'none')+
    ggtitle("Mean Squared Errors for different Models predicting Fraction Incarcerated",
            "Red line indicates MSE for null model (always guessing the mean)")
     
```


Modeling the probability of Black children born/living in the tract in 1980 reaching the top 20% of incomes in 2010 based on our typologies and neighborhood racial proportions.
```{r modeling probability of reaching top 20%}
# make a df just for this IV
top_20 <- df_full %>% 
  select(starts_with('kfr_top20'), starts_with('prop'), ends_with('dmmy'), starts_with('LQ'), contains('type'), TRTID10) %>%
  mutate_all(funs(replace(., is.na(.), 0))) %>% filter(kfr_top20_pooled_pooled_mean >0)

#fit models for proportion, ntype, location q, and clustering
model_prop <- betareg(kfr_top20_pooled_pooled_mean ~ prop.nhwht80 + prop.nhblk80 + prop.asian80 + prop.hisp80, data = top_20)

model_ntype <- betareg(kfr_top20_pooled_pooled_mean ~ collapsed_type, data = top_20)

# this one sometimes doesn't converge when I use the whole set, so I use a sample 
model_lq <- betareg(kfr_top20_pooled_pooled_mean ~ LQ_white_80 + LQ_black_80 + LQ_asian_80 + LQ_native_80, data = top_20 %>% sample_n(10000))

model_cluster <- betareg(kfr_top20_pooled_pooled_mean ~ wht.clst.dmmy + blk.clst.dmmy + as.clst.dmmy + hisp.clst.dmmy, data = top_20)
model_cluster_prop <- betareg(kfr_top20_pooled_pooled_mean ~ wht.clst.dmmy + blk.clst.dmmy + as.clst.dmmy + hisp.clst.dmmy + prop.nhwht80 + prop.nhblk80 + prop.asian80 + prop.hisp80, data = top_20)
knitr::kable(tibble(name = names(coef(model_cluster_prop)), pe = coef(model_cluster_prop), se = sqrt(diag(vcov(model_cluster_prop)))))
```

Actual vs predicted plots to check in-sample fit
```{r actual vs predicted plots}
bins = 40 # set the number of bins
 # function which takes a model and spits out a dataframe formatted to make an avp plot

# row bind the results for each model
plot_df <- bind_rows(prep_avp_df(model_cluster$y, model_cluster$fitted.values, bins, 'cluster'),
          prep_avp_df(model_lq$y, model_lq$fitted.values, bins, 'location quotient'),
          prep_avp_df(model_ntype$y, model_ntype$fitted.values, bins, 'neighborhood type'),
          prep_avp_df(model_prop$y, model_prop$fitted.values, bins, 'racial proportion'),
          prep_avp_df(model_cluster_prop$y, model_cluster_prop$fitted.values, bins, 'racial proportion + clusters')) %>% mutate(race_plus_clusters = if_else(model == 'racial proportion + clusters', TRUE, FALSE))


# plot comparison
ggplot(plot_df, aes(x = predicted, y = actual, color = model, shape = race_plus_clusters))+
    geom_point(alpha = .5, size = 2.5)+
    geom_abline(aes(slope = 1, intercept = 0), color = 'red')


clust_test <- top_20 %>% select(ends_with('dmmy'), TRTID10) %>% 
  mutate(x = model_cluster_prop$fitted.values, y =model_cluster_prop$y) %>%
  gather(dummy_type, exists, -TRTID10, -x, -y) %>% 
  mutate(clusters = if_else(exists==1,dummy_type, '')) %>% 
  spread(dummy_type, clusters, fill = '') %>% group_by(TRTID10) %>%
  summarise(dummy_type = str_c(as.clst.dmmy, blk.clst.dmmy, hisp.clst.dmmy, wht.clst.dmmy, collapse = ' '), x = first(x), y = first(y), 
         dummy_type = if_else(dummy_type=='', 'none', dummy_type)) %>% 
  select(TRTID10, dummy_type, x, y) %>% inner_join(top_20)
  
ggplot(clust_test 
       %>% filter(str_detect(dummy_type,'blk'))
       , aes(x, y, color = dummy_type))+
    geom_point(aes(alpha = prop.nhblk80))+
    facet_wrap(~dummy_type)+
    geom_abline(aes(slope = 1, intercept = 0), color = 'red')
    
mean_guess <- mse_calc(fitted_values = mean(top_20$kfr_top20_pooled_pooled_mean), y = top_20$kfr_top20_pooled_pooled_mean) # assign the mean guess to a variable
tibble( # make a tibble
  cluster = mse_calc(model_cluster), # then for each model
  loc_quotient = mse_calc(model_lq),
  neighborhood_type = mse_calc(model_ntype),
  proportion = mse_calc(model_prop),
  cluster_prop = mse_calc(model_cluster_prop)
) %>% gather() %>% # gather to long format
  ggplot(aes(value, key, color = key))+ # and plot
    geom_point()+
    geom_vline(aes(xintercept = mean_guess), color = 'red')+ # make a red vertical line for the mse of just guessing the mean value
    theme_minimal()+
    theme(legend.position = 'none')+
    ggtitle("Mean Squared Errors for different Models predicting Probability of entering top 20%",
            "Red line indicates MSE for null model (always guessing the mean)")
    
```

```{r same as above but with CV}


mean_guess <- mse_calc(fitted_values = mean(top_20$kfr_top20_pooled_pooled_mean), y = top_20$kfr_top20_pooled_pooled_mean) # assign the mean guess to a variable

model_prop <- betareg(kfr_top20_pooled_pooled_mean ~ prop.nhwht80 + prop.nhblk80 + prop.asian80 + prop.hisp80, data = top_20)

model_ntype <- betareg(kfr_top20_pooled_pooled_mean ~ collapsed_type, data = top_20)

# this one sometimes doesn't converge when I use the whole set, so I use a sample
model_lq <- betareg(kfr_top20_pooled_pooled_mean ~ LQ_white_80 + LQ_black_80 + LQ_asian_80 + LQ_native_80, data = top_20 %>% sample_n(10000))

model_cluster <- betareg(kfr_top20_pooled_pooled_mean ~ wht.clst.dmmy + blk.clst.dmmy + as.clst.dmmy + hisp.clst.dmmy, data = top_20)
model_cluster_prop <- betareg(kfr_top20_pooled_pooled_mean ~ wht.clst.dmmy + blk.clst.dmmy + as.clst.dmmy + hisp.clst.dmmy + prop.nhwht80 + prop.nhblk80 + prop.asian80 + prop.hisp80, data = top_20)

y = top_20[['kfr_top20_pooled_pooled_mean']]
cv_top_20 <- tibble( # make a tibble
  cluster = cv_model(x = top_20 %>% select(wht.clst.dmmy, blk.clst.dmmy, as.clst.dmmy, hisp.clst.dmmy),
             y = y, 
             k = k, 
             model = 'betareg', 
             scoring_function = 'mse_calc'), # then for each model
  loc_quotient = cv_model(top_20 %>% select(LQ_white_80, LQ_black_80, LQ_asian_80, LQ_native_80),
                          y,k, 'betareg', 'mse_calc'),
  neighborhood_type = cv_model(top_20['collapsed_type'],y,k, 'betareg', 'mse_calc'),
  proportion = cv_model(top_20 %>% select(prop.nhwht80, prop.nhblk80, prop.asian80, prop.hisp80),
                        y,k, 'betareg', 'mse_calc'),
  cluster_prop = cv_model(top_20 %>% select(wht.clst.dmmy, blk.clst.dmmy, as.clst.dmmy, hisp.clst.dmmy,prop.nhwht80, prop.nhblk80, prop.asian80, prop.hisp80),
                          y,k, 'betareg', 'mse_calc')
) %>% gather()# gather to long format

function(formula_call, data, k, model = 'glm', scoring_function = 'mse_calc', ...)
cv_model(formula_call = kfr_top20_pooled_pooled_mean ~ collapsed_type, data = top_20, k = 5)

ggplot(cv_top_20, aes(value, key, color = key))+ # and plot
  geom_point()+
  geom_vline(aes(xintercept = mean_guess), color = 'red')+ # make a red vertical line for the mse of just guessing the mean value
  theme_minimal()+
  theme(legend.position = 'none')+
  ggtitle("Mean Squared Errors for different Models predicting Probability of entering top 20%",
          "Red line indicates MSE for null model (always guessing the mean)")

```

```{r cfs for top_20}
model_cluster_prop <- betareg(kfr_top20_pooled_pooled_mean ~ wht.clst.dmmy + blk.clst.dmmy + as.clst.dmmy + hisp.clst.dmmy + prop.nhwht80 + prop.nhblk80 + prop.asian80 + prop.hisp80, data = top_20)


# to make CFs, I take the means of all variables grouped by neighborhood type
cfs_20 <- top_20  %>% dplyr::select(-type) %>% group_by(collapsed_type) %>% summarise_all(mean, na.rm = TRUE) %>% mutate_at(vars(ends_with('dmmy')), round)
cfs_20 <- cfs_20 %>% mutate(
  p_cluster_prop = predict(model_cluster_prop, cfs_20, type = 'response'),
  p_cluster = predict(model_cluster, cfs_20, type = 'response'),
  p_lq = predict(model_lq, cfs_20, type = 'response'),
  p_ntype = predict(model_ntype, cfs_20, type = 'response'),
  p_prop = predict(model_prop, cfs_20, type = 'response')) %>% gather(model, prediction, starts_with('p_')) %>% filter(!collapsed_type %in% c('0', 'empty'))

ggplot(cfs_20, aes(x = prediction, y = reorder(collapsed_type, -prediction)))+
  geom_point(aes(color = model))+
  geom_point(aes(x = kfr_top20_pooled_pooled_mean), alpha = .3)+
  theme_minimal()
```

